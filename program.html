
<!DOCTYPE HTML>


<!--
 Berkeley Vision and Learning Center (BVLC)
 
 Design based on:
 Strongly Typed 1.0 by HTML5 UP
 html5up.net | @n33co
 Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
 -->
<html>
    <head>
        <title>WiCV</title>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <meta name="viewport" content="width=1040" />
        <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600|Arvo:700" rel="stylesheet" type="text/css" />
        <!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
        <script src="js/jquery.min.js"></script>
        <script src="js/jquery.dropotron.js"></script>
        <script src="js/jquery.dotdotdot.min.js"></script>
        <script src="js/config.js"></script>
        <script src="js/skel.min.js"></script>
        <script src="js/skel-panels.min.js"></script>
        <script src="js/jquery.slides.min.js"></script>
        <link rel="stylesheet" href="css/font-awesome.min.css">
            <noscript>
                <link rel="stylesheet" href="css/style.css" />
                <link rel="stylesheet" href="css/style-desktop.css" />
                <link rel="stylesheet" href="css/skel-noscript.css" />
            </noscript>
        
        <style>
        
        /* Style the tab */
        div.tab {
            margin: auto;
            width: 75%;
            padding: 0px 12px; 
            overflow: hidden;
            border: 1px solid #ccc;
            background-color: #f1f1f1;
        }
        
        /* Style the buttons inside the tab */
        div.tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
            font-size: 17px;
        }
        
        /* Change background color of buttons on hover */
        div.tab button:hover {
            background-color: #ddd;
        }
        
        /* Create an active/current tablink class */
        div.tab button.active {
            background-color: #ccc;
        }
        
        /* Style the tab content */
        .tabcontent {
            margin: auto;
            width: 75%;
            display: none;
            padding: 6px 12px;
            border: 1px solid #ccc;
            border-top: none;
        }
        </style>

            </head>
    <body class="homepage">
        <!-- Header Wrapper -->
        <div id="header-wrapper">
            <!-- Header -->
            <div id="header" class="container">
                <!-- Logo -->
                <!--<h1 id="logo">
                 <a id="home" href="#"></a>
                 </h1>-->
                <!-- Nav -->
                <nav id="nav">
                    <ul style="padding-top: 10px; padding-bottom: 2em">
                        <li>
                            <a href="index.html#header" class="">
                                <span style="
                                    position: relative;
                                    width: 261px;
                                    display: inline-block;
                                    height: 10px;
                                    ">
                                    <img src="images/wicv_logo_simple.png" style="
                                    position: absolute;
                                    left: 0;
                                    width: 111px;
                                    top: -20px;
                                    "/>
                                </span>
                            </a>
                        </li>
                        
                        <li>
                            <a href="index.html#header"><span>Home</span></a>
                        </li>
                        <li>
                            <a href="program.html"><span>Program</span></a>
                        </li>
                        <li>
                            <a href="faq.html"><span>FAQ</span></a>
                        </li>
                        <li>
                            <a href="committee.html"><span>Committee</span></a>
                        </li>
                        <li>
                            <a href="participation.html"><span>Call for Participation</span></a>
                        </li>
                        <li>
                            <a href="contact.html"><span>Contact</span></a>
                            
                        </li>
                        <li>
                           <a href="#"><span>WiCV</span></a>
                           <ul>
                              <li><a href="https://sites.google.com/site/wicv2016/home">WiCV 2016</a></li>
                              <li><a href="https://sites.google.com/site/wicv2015/home">WiCV 2015</a></li>
                           </ul>
                        </li>
                    </ul>
                </nav>
            </div>
        </div>
        
        <div class="banner-wrapper">
            <div class="inner">
                <!-- Banner -->
                <section class="banner container">
                    <br>
                    <h2 id="faculty">Program</h2>
                    
                </section>
            </div>
        </div>
        <div class="features-wrapper">
                  
        <p style="color:red;"><strong>* Check back later for the final schedule. * </strong></p>

        <div class="tab">
          <button class="tablinks" onclick="openCity(event, 'Schedule')" id="defaultOpen">Schedule</button>
          <button class="tablinks" onclick="openCity(event, 'Talks')">Talks</button>
          <button class="tablinks" onclick="openCity(event, 'Panel')">Panel</button>
          <button class="tablinks" onclick="openCity(event, 'Orals')">Orals</button>
          <button class="tablinks" onclick="openCity(event, 'Posters')">Posters</button>
          <button class="tablinks" onclick="openCity(event, 'Dinner')">Dinner</button>
        </div>
        
        <div id="Schedule" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Schedule on July 26</h3>
          <h5 style="color:red;font-style:italic; margin: 0px 0px 20px 0px;">tentative</h5>
          <p style="margin: 0px 0px 20px 40px;text-align:left;">
                1:30 - 1:40 pm &emsp;&emsp;<b>Introduction</b> <br>
                1:40 - 2:00 pm &emsp;&emsp;<b>Keynote</b><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Learning to Segment Moving Objects, by <a href="http://thoth.inrialpes.fr/~schmid/">Cordelia Schmid (INRIA)</a> <br>
                2:00 - 2:30 pm &emsp;&emsp;<b>Oral Session 1</b><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Gaze Embeddings for Zero-Shot Image Classification, by Nour Karessli (Max Planck Institute for Informatics)<br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Towards Better Instance-level Recognition, by Georgia Gkioxari (Facebook AI Research)<br>
                2:30 - 2:50 pm &emsp;&emsp;<b>Keynote</b><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;TBA by <a href="http://www.xrce.xerox.com/About-XRCE/People/Naila-Murray">Naila Murray (XRCE)</a><br>
                2:50 - 4:15 pm &emsp;&emsp;<b>Poster Session and Coffee Break</b><br>
                4:15 - 4:35 pm &emsp;&emsp;<b>Keynote</b><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;TBA by <a href="http://researcher.watson.ibm.com/researcher/view.php?person=jp-CHIE">Chieko Asakawa (IBM Research)</a>  <br>
                4:35 - 5:05 pm &emsp;&emsp;<b>Oral Session 2</b> <br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Dynamic Deep Neural Networks: Optimizing Accuracy-Efficiency Trade-offs by Selective Execution, by Lanlan Liu (University of Michigan)<br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Semi and Weakly Supervised Semantic Segmentation Using Generative Adversarial Network, by Nasim Souly (University of Central Florida)<br>
                5:05 - 5:35 pm &emsp;&emsp;<b>Panel session</b><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="http://researcher.watson.ibm.com/researcher/view.php?person=jp-CHIE">Chieko Asakawa (IBM Research)</a><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a  href="https://clarifai.com/">Andrea Frome (Clarifai)</a><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="http://raiahadsell.com/index.html">Raia Hadsell (DeepMind)</a><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="http://www.xrce.xerox.com/About-XRCE/People/Naila-Murray">Naila Murray (XRCE)</a><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="http://thoth.inrialpes.fr/~schmid/">Cordelia Schmid (INRIA)</a><br>
                &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="http://www.tandemlaunch.com">Helge Seetzen (TandemLaunch)</a><br>
                5:35 - 5:45 pm &emsp;&emsp;<b>Closing Remarks</b> <br>
          </p>

        </div>
        
        <div id="Talks" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Keynote Talks</h3>
          <p>Keynote speakers will give technical talks about their research in computer vision.</p> 


            <!-- Chieko Asakawa --> 
            <div class="row">
            <div class="4u"> 
                <a href="http://researcher.watson.ibm.com/researcher/view.php?person=jp-CHIE" class="image image-centered"><img height=230 width=120 src="images/speakers/chiekoasakawa.png" alt="" /></a>
                <strong>Chieko Asakawa, IBM Research</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                     Chieko Asakawa is a blind Japanese computer scientist, known for her work at IBM Research – Tokyo in accessibility. A Netscape browser plug-in which she developed, the IBM Home Page Reader, became the most widely used web-to-speech system available. She is the recipient of numerous industry and government awards. Asakawa was born with normal sight, but after she injured her optic nerve in a swimming accident at age 11, she began losing her sight, and by age 14 she was fully blind. She earned a bachelor's degree in English literature at Otemon Gakuin University in Osaka in 1982 and then began a two-year computer programming course for blind people using an Optacon to translate print to tactile sensation. Chieko joined IBM in 1985 after completing the computer science courses for the blind at Nippon Lighthouse. She received a B.A. degree in English literature from Otemon Gakuin University in 1982, and a Ph.D in Engineering from the University of Tokyo in 2004. She is a member of the Association for Computing Machinery (ACM), the Information Processing Society of Japan, and IBM Academy of Technology. She was inducted into the Women in Technology International (WITI) Hall of Fame in 2003, and both within and outside of IBM, she has been actively working to help women engineers pursue technical careers. Chieko was appointed to IBM Fellow in 2009, IBM's most prestigious technical honor. In 2013, the government of Japan awarded the Medal of Honor with Purple Ribbon to Chieko for her outstanding contributions to accessibility research, including the development of the voice browser for the visually impaired.
                  </p> 
              </div>
            </div>          

            <!-- Naila Murray --> 
            <div class="row">
              <div class="4u"> 
                  <a href="http://www.xrce.xerox.com/About-XRCE/People/Naila-Murray" class="image image-centered"><img height=230 width=120 src="images/speakers/nailamurray.jpg" alt="" /></a>
                  <strong>Naila Murray, XRCE</strong>
              </div>    
              <div class="8u">         
              <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                  Naila Murray obtained a B.Sc. in Electrical Engineering from Princeton University, U.S.A., in 2007. From 2008 to 20012, she worked as a doctoral candidate in the Colour in Context (CIC) group at the Computer Vision Center in the Unversitat Autonoma de Barcelona. She was a visiting researcher at Xerox Research Centre Europe (XRCE) from 2011-2012 in the framework of a joint project between CV and CIC. She joined XRCE in January 2013. She is a senior scientist and manager of the Computer Vision (CV) group at XRCE. Her research interests include scene understanding, visual attention and image aesthetics analysis. Currently, her research focuses on fine-grained visual categorization and object detection.
                  </p> 
              </div>
            </div>

          <!-- Cordelia Schmid -->            
          <div class="row">
            <div class="4u"> 
                <a href="http://thoth.inrialpes.fr/~schmid/" class="image image-centered"><img height=230 width=120 src="images/speakers/cordeliaschmid.jpg" alt="" /></a>
                <strong>Cordelia Schmid, INRIA</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                    Cordelia Schmid holds a M.S. degree in Computer Science from the University of Karlsruhe and a Doctorate, also in Computer Science, from the Institut National Polytechnique de Grenoble (INPG). Her doctoral thesis on "Local Greyvalue Invariants for Image Matching and Retrieval" received the best thesis award from INPG in 1996. She received the Habilitation degree in 2001 for her thesis entitled "From Image Matching to Learning Visual Models".  Dr. Schmid was a post-doctoral research assistant in the Robotics Research Group of Oxford University in 1996--1997. Since 1997 she has held a permanent research position at INRIA Rhone-Alpes, where she is a research director and directs an INRIA team. Dr. Schmid is the author of over a hundred technical publications. She has been an Associate Editor for IEEE PAMI (2001--2005) and for IJCV (2004--2012), editor-in-chief for IJCV (2013---), a program chair of IEEE CVPR 2005 and ECCV 2012 as well as a general chair of IEEE CVPR 2015. In 2006, 2014 and 2016, she was awarded the Longuet-Higgins prize for fundamental contributions in computer vision that have withstood the test of time. She is a fellow of IEEE. In 2013, she was awarded an ERC advanced grant on "Active Large-scale LEarninG for visual RecOgnition" and in 2015 a Humboldt Research Award.
                  </p> 
              </div>
            </div>          

        </div> <!-- Talks end --> 
        
        <div id="Panel" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Panel</h3>
          <p>Panelists will answer questions and discuss about increasing diversity in computer vision.</p>


            <!-- Chieko Asakawa --> 
            <div class="row">
            <div class="4u"> 
                <a href="http://researcher.watson.ibm.com/researcher/view.php?person=jp-CHIE" class="image image-centered"><img height=230 width=120 src="images/speakers/chiekoasakawa.png" alt="" /></a>
                <strong>Chieko Asakawa, IBM Research</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                     Chieko Asakawa is a blind Japanese computer scientist, known for her work at IBM Research – Tokyo in accessibility. A Netscape browser plug-in which she developed, the IBM Home Page Reader, became the most widely used web-to-speech system available. She is the recipient of numerous industry and government awards. Asakawa was born with normal sight, but after she injured her optic nerve in a swimming accident at age 11, she began losing her sight, and by age 14 she was fully blind. She earned a bachelor's degree in English literature at Otemon Gakuin University in Osaka in 1982 and then began a two-year computer programming course for blind people using an Optacon to translate print to tactile sensation. Chieko joined IBM in 1985 after completing the computer science courses for the blind at Nippon Lighthouse. She received a B.A. degree in English literature from Otemon Gakuin University in 1982, and a Ph.D in Engineering from the University of Tokyo in 2004. She is a member of the Association for Computing Machinery (ACM), the Information Processing Society of Japan, and IBM Academy of Technology. She was inducted into the Women in Technology International (WITI) Hall of Fame in 2003, and both within and outside of IBM, she has been actively working to help women engineers pursue technical careers. Chieko was appointed to IBM Fellow in 2009, IBM's most prestigious technical honor. In 2013, the government of Japan awarded the Medal of Honor with Purple Ribbon to Chieko for her outstanding contributions to accessibility research, including the development of the voice browser for the visually impaired.
                  </p> 
              </div>
            </div>          

            <!-- Andrea Frome --> 
            <div class="row">
            <div class="4u"> 
                <a href="https://clarifai.com/" class="image image-centered"><img height=230 width=120 src="images/speakers/andreafrome.jpg" alt="" /></a>
                <strong>Andrea Frome, Clarifai</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                  Dr. Andrea Frome earned her Ph.D. in Computer Science and Machine Learning in Jitendra Malik’s lab at UC Berkeley in 2007. Since then, her work in computer vision and machine learning has included: leading the visual recognition team within Street View which is especially known for its work blurring faces and license plates;  as a member of the Google Brain team, developing DeViSE for combining visual recognition with word embeddings and applying an attention RNN to fine-grained classification; and work on systems for Hillary for America at campaign headquarters for identity resolution and automatically reading canvassing surveys to reduce data entry. In January 2017, she joined Clarifai as Director of Research. Her non-work pursuits include doing volunteer work for <a href="flippable.org">flippable.org</a>, studying flying trapeze, and learning Argentine Tango.
                  </p> 
              </div>
            </div>          

            <!-- Raia Hadsell  --> 
            <div class="row">
            <div class="4u"> 
                <a href="http://raiahadsell.com/index.html" class="image image-centered"><img height=230 width=120 src="images/speakers/raiahadsell.jpg" alt="" /></a>
                <strong>Raia Hadsell, DeepMind</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                  Raia Hadsell, a senior research scientist at DeepMind, has worked on deep learning and robotics problems for over 10 years. Her early research developed the notion of manifold learning using Siamese networks, which has been used extensively for invariant feature learning. After completing a PhD with Yann LeCun, which featured a self-supervised deep learning vision system for a mobile robot, her research continued at Carnegie Mellon’s Robotics Institute and SRI International, and in early 2014 she joined DeepMind in London to study artificial general intelligence. Her current research focuses on the challenge of continual learning for AI agents and robots. While deep RL algorithms are capable of attaining superhuman performance on single tasks, they often cannot transfer that performance to additional tasks, especially if experienced sequentially. She has proposed neural approaches such as policy distillation, progressive nets, and elastic weight consolidation to solve the problem of catastrophic forgetting for agents and robots. 
                  </p> 
              </div>
            </div>          


            <!-- Naila Murray --> 
            <div class="row">
              <div class="4u"> 
                  <a href="http://www.xrce.xerox.com/About-XRCE/People/Naila-Murray" class="image image-centered"><img height=230 width=120 src="images/speakers/nailamurray.jpg" alt="" /></a>
                  <strong>Naila Murray, XRCE</strong>
              </div>    
              <div class="8u">         
              <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                  Naila Murray obtained a B.Sc. in Electrical Engineering from Princeton University, U.S.A., in 2007. From 2008 to 20012, she worked as a doctoral candidate in the Colour in Context (CIC) group at the Computer Vision Center in the Unversitat Autonoma de Barcelona. She was a visiting researcher at Xerox Research Centre Europe (XRCE) from 2011-2012 in the framework of a joint project between CV and CIC. She joined XRCE in January 2013. She is a senior scientist and manager of the Computer Vision (CV) group at XRCE. Her research interests include scene understanding, visual attention and image aesthetics analysis. Currently, her research focuses on fine-grained visual categorization and object detection.
                  </p> 
              </div>
            </div>

          <!-- Cordelia Schmid -->            
          <div class="row">
            <div class="4u"> 
                <a href="http://thoth.inrialpes.fr/~schmid/" class="image image-centered"><img height=230 width=120 src="images/speakers/cordeliaschmid.jpg" alt="" /></a>
                <strong>Cordelia Schmid, INRIA</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                    Cordelia Schmid holds a M.S. degree in Computer Science from the University of Karlsruhe and a Doctorate, also in Computer Science, from the Institut National Polytechnique de Grenoble (INPG). Her doctoral thesis on "Local Greyvalue Invariants for Image Matching and Retrieval" received the best thesis award from INPG in 1996. She received the Habilitation degree in 2001 for her thesis entitled "From Image Matching to Learning Visual Models".  Dr. Schmid was a post-doctoral research assistant in the Robotics Research Group of Oxford University in 1996--1997. Since 1997 she has held a permanent research position at INRIA Rhone-Alpes, where she is a research director and directs an INRIA team. Dr. Schmid is the author of over a hundred technical publications. She has been an Associate Editor for IEEE PAMI (2001--2005) and for IJCV (2004--2012), editor-in-chief for IJCV (2013---), a program chair of IEEE CVPR 2005 and ECCV 2012 as well as a general chair of IEEE CVPR 2015. In 2006, 2014 and 2016, she was awarded the Longuet-Higgins prize for fundamental contributions in computer vision that have withstood the test of time. She is a fellow of IEEE. In 2013, she was awarded an ERC advanced grant on "Active Large-scale LEarninG for visual RecOgnition" and in 2015 a Humboldt Research Award.
                  </p> 
              </div>
            </div>          

            <!-- Helge Seetzen  --> 
            <div class="row">
            <div class="4u"> 
                <a href="http://www.tandemlaunch.com" class="image image-centered"><img height=230 width=120 src="images/speakers/helgeseetzen.png" alt="" /></a>
                <strong>Helge Seetzen, TandemLaunch</strong>
              </div>      
              <div class="8u">
                <p style="text-align:justify;font-size:0.75em;line-height: 1.2;">
                 Helge is an award-winning technologist, entrepreneur, and a recognized global authority on technology transfer and display technologies. As General Partner of TandemLaunch, he works with inventors and entrepreneurs to build high growth technology companies. His past successes include the transformation of raw university IP into fully commercialized LED TV technology, including selling his last company - Brightside Technologies - to Dolby Laboratories after sealing partnerships with several of the largest consumer electronics companies in the world. Helge holds over 80 patents in the fields of display, camera and video technology.
                  </p> 
              </div>
            </div>          
        </div> <!-- Panel end --> 

        <div id="Orals" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Orals</h3>
          <p>A few accepted abstracts will be invited to give an oral presentation. We will add presenter instructions soon.</p>
        </div>

        <div id="Posters" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Posters</h3>
          <p>Authors of all accepted abstracts (with or without travel grant) will present their work in a poster session. We will add presenter instructions soon.</p>
        </div>

        <div id="Dinner" class="tabcontent">
          <h3 style="margin: 20px 0px 0px 0px;">Mentoring dinner on July 25</h3>
          <p style="font-style:italic;">by invitation only</p>
          <p>6:30 - 9:30 pm   Dinner sponsored by NVIDIA (details TBA)</p>
          <p align="left";>The dinner event is an opportunity to meet other female computer vision researchers. Poster presenters will be matched with senior computer vision researchers to share experience and career advice. Invitees will receive an e-mail and be asked to confirm attendance.</p>
          <p align="left";><b>*Note that the dinner takes place the evening before the main workshop day.*</b></p>
        </div>

        <script>
           function openCity(evt, cityName) {
               var i, tabcontent, tablinks;
               tabcontent = document.getElementsByClassName("tabcontent");
               for (i = 0; i < tabcontent.length; i++) {
                   tabcontent[i].style.display = "none";
               }
               tablinks = document.getElementsByClassName("tablinks");
               for (i = 0; i < tablinks.length; i++) {
                   tablinks[i].className = tablinks[i].className.replace(" active", "");
               }
               document.getElementById(cityName).style.display = "block";
               evt.currentTarget.className += " active";
           }
           
           // Get the element with id="defaultOpen" and click on it
           document.getElementById("defaultOpen").click();
        </script>

          <br><br><br><br><br> 
        </div>
        <!-- Footer Wrapper -->
        <div class="footer">
            <div class="container">
                    <div class="row">
                            <div class="7u">
             <p>&copy; WiCV 2017</p>
            </div>
            <div class="1u">
                   <a href="mailto:wicv17-organizers@googlegroups.com" class="fa fa-envelope" style="font-size:1.25em;" data-placement="top" data-toggle="tooltip" title="Email"></a>
                       </div>
                       <div class="1u">                       
                                                        <a href="https://twitter.com/wicvworkshop" class="fa fa-twitter" data-placement="top" style="font-size:1.25em;"  data-toggle="tooltip" title="Twitter"></a>
                                                     </div>
                                                         <div class="1u">
                                                               <a href="https://www.facebook.com/WomenInComputerVision/" class="fa fa-facebook" data-placement="top" style="font-size:1.25em;" data-toggle="tooltip" title="Facebook"></a>
                                                               </div>
                                                           </div>
                                                           </div>
                                                         </div>
        <script src="//static.getclicky.com/js" type="text/javascript"></script>
        <script type="text/javascript">try{ clicky.init(100926441); }catch(e){}</script>
        <noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/100926441ns.gif" /></p></noscript>
    </body>
</html>
